{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/dino-dragon-model/dino_dragon_10_0.899.h5 -O dino-dragon.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ddf5b3",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the converted model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4a86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a472ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('dino-dragon.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3e564",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "To be able to use this model, we need to know the index of the input and the index of the output.\n",
    "\n",
    "What's the output index for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b692a26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.lite as tflite\n",
    "interpreter = tflite.Interpreter(model_path='dino-dragon.tflite')\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebcff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6050c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b6fe9b",
   "metadata": {},
   "source": [
    "## Preparing the image\n",
    "\n",
    "You'll need some code for downloading and resizing images. You can use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb350ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db135606",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Smaug_par_David_Demaret.jpg/1280px-Smaug_par_David_Demaret.jpg\"\n",
    "\n",
    "image = download_image(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14385df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = prepare_image(image, (150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675a965",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now we need to turn the image into numpy array and pre-process it.\n",
    "\n",
    "Tip: Check the previous homework. What was the pre-processing we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8fb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-image-helper\n",
    "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08ca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow.lite as tflite\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963d2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path='dino-dragon.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91541078",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = create_preprocessor('xception', target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessor.from_url(img_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa0f5b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's apply this model to this image. What's the output of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc872393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpreter.set_tensor(input_index, X)\n",
    "#interpreter.invoke()\n",
    "#preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771de491",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae1a66",
   "metadata": {},
   "source": [
    "## Question 5 & 6 -  predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fb5428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
